{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-the-oasis-project","title":"Welcome to the O.A.S.I.S. Project","text":"<p>Welcome to the O.A.S.I.S. Project, where the frontier of technology blends with human creativity to redefine what's possible beyond the pages of science fiction. Standing for Open Armor Systems Integrated Suite, O.A.S.I.S. is at the forefront of wearable technology, drawing inspiration from iconic innovations akin to those of Tony Stark. The essence of O.A.S.I.S. lies not just in its origins within high-tech costumes but in its promise for wide-ranging applications that empower and inspire.</p>"},{"location":"#hardware-ecosystem","title":"Hardware Ecosystem","text":"<p>At the heart of the O.A.S.I.S. Project lies the NVIDIA Jetson platform, with current support for the Orin Nano/NX and the Xavier NX. These platforms are chosen for their computational capabilities and flexibility, designed to handle complex processing tasks effortlessly. Yet, the horizon of hardware compatibility is ever-expanding, with the Raspberry Pi 5 next in line, promising to bring even more versatility and accessibility to the project.</p>"},{"location":"#software-foundations","title":"Software Foundations","text":"<p>The foundation of the O.A.S.I.S. Project is built upon NVIDIA's comprehensive Linux image and SDK, providing the essential tools needed for development. For instructions on how to get started, refer to the official NVIDIA guide. Our ambition doesn't end with the present; we're also in the process of crafting a custom OS designed for embedded platforms to optimize performance and streamline operations.</p>"},{"location":"#your-pathway-to-innovation","title":"Your Pathway to Innovation","text":"<p>Explore the future by consulting our detailed guide, which will assist you in integrating the NVIDIA image with the O.A.S.I.S. project's core. This path is crafted for innovators and visionaries eager to make a significant impact.</p> <p>Join us in this venture, where technology meets imagination, and become part of a community dedicated to pushing the boundaries of what's possible. Welcome to the O.A.S.I.S. Project\u2014where the future is forged.</p>"},{"location":"#documentation-notes","title":"Documentation Notes","text":"<p>First, thank you for your interest in the project! You are clearly a well-educated individual, as well as imaginative and forward thinking.</p> <p>Next up, please keep in mind that this documentation is heavily a work in process. It is not complete. It is still evolving.</p> <p>Finally, if you see something missing that you must know (or are mildly curious about), please hit me up for more info/details: kris@kerseyfabrications.com</p>"},{"location":"#where-to-begin","title":"Where to begin?","text":"<p>Probably the M.I.R.A.G.E. page. It was the first part of the project and the documentation reflects that a bit. While there should be most of what you need in each project's page, not all \"getting started\" may be on each page.</p>"},{"location":"#how-to-support-this-project","title":"How to Support This Project!","text":"<p>Your involvement and support are crucial to the success and growth of the O.A.S.I.S. Project! Here are some ways you can help:</p> <ul> <li> <p>Spread the Word: Share information about the project with friends, colleagues, and on your social media platforms. The more people know about our efforts, the greater our impact can be.</p> </li> <li> <p>Give It a Try Yourself: Download the software, experiment with it, and provide feedback. Your hands-on experience is invaluable and can help shape future developments.</p> </li> <li> <p>Contribute Code, Models, Etc.: If you're a developer, designer, or content creator, consider contributing your skills and resources. Whether it's improving the codebase, enhancing the design, or offering new models, your contributions are welcome.</p> </li> <li> <p>Watch, Like, and Subscribe on YouTube: Follow my YouTube channels, The OASIS Project and Kersey Fabrications. Engage with my content by liking, commenting, and subscribing. This helps increase my visibility and reach.</p> </li> <li> <p>Support Financially Through: If you find value in what I'm creating and would like to contribute financially, consider supporting me on Patreon. Every bit helps me continue my work and keep the project moving forward.</p> </li> </ul> <p>Your support in any form makes a huge difference and is deeply appreciated!</p>"},{"location":"#general-notes-and-disclosures","title":"General Notes and Disclosures","text":""},{"location":"#indemnification","title":"Indemnification","text":"<p>Terms of Service for all Kersey Fabrications projects: Google Drive Link</p>"},{"location":"#affiliate-links","title":"Affiliate Links","text":"<p>This project, in part, is supported by affiliate links.</p> <p>For Amazon Links: As an Amazon Associate I earn from qualifying purchases.</p> <p>For Other Purchase Links: Other product links may be affiliate links that I also earn from.</p>"},{"location":"aura/","title":"A.U.R.A.","text":""},{"location":"aura/#aura-advanced-utility-for-reliable-acquisition-embedded-helmet-firmware","title":"A.U.R.A - Advanced Utility for Reliable Acquisition (Embedded Helmet Firmware)","text":"<p>This code is a healthy mix of example code from various libraries with a special thanks to Adafruit for their awesome hardware and software.</p> <p>Note: I will have a circuit diagram in the future. This is a pretty simple one though. All of the devices are I2C devices that can be daisy-chained and it's powered by USB.</p>"},{"location":"aura/#hardware","title":"Hardware","text":"<ul> <li>Teensy 4.0 - Main Processor</li> <li>Adafruit LSM6SDSOX+LIS3MDL - 9-DOF Sensor</li> <li>Adafruit Mini GPS - GPS</li> <li>Adafruit HTS221 Humidity Sensor - Temperature and Humidity Sensor</li> <li>128x64 OLED Display - Optional: This was used to tune the system, especially the motorization that's in progress.</li> </ul>"},{"location":"aura/#libraries","title":"Libraries","text":"<ul> <li>SPI</li> <li>Wire</li> <li>Adafruit GFX Library</li> <li>Adafruit SSD1306</li> <li>Adafruit Sensor Calibration</li> <li>Adafruit GPS Library</li> <li>Adafruit HTS221</li> <li>Servo (for PWMServo)</li> <li>Bounce2</li> <li>Adafruit Seesaw</li> <li>ArduinoJson</li> <li>Adafruit AHRS</li> <li>Adafruit LSM6DS</li> </ul>"},{"location":"aura/#building","title":"Building","text":"<p>This firmware is currently being built in the Arduino IDE using the libraries and target hardware mentioned above.</p>"},{"location":"beacon/","title":"B.E.A.C.O.N. Parts Catalog","text":""},{"location":"beacon/#beacon-blueprint-engineering-and-component-organizational-nexus-cad-files","title":"B.E.A.C.O.N. - Blueprint Engineering And Component Organizational Nexus (CAD Files)","text":""},{"location":"beacon/#parts-catalog","title":"Parts Catalog","text":""},{"location":"beacon/#hud-mounting","title":"HUD Mounting","text":""},{"location":"beacon/#misc-mechanical-parts","title":"Misc. Mechanical Parts","text":""},{"location":"beacon/#remote-control","title":"Remote Control","text":""},{"location":"beacon/#speakers","title":"Speakers","text":""},{"location":"beacon/#wearable-systems","title":"Wearable Systems","text":""},{"location":"comms/","title":"Communications","text":""},{"location":"comms/#the-oasis-project-communication-protocols","title":"The O.A.S.I.S. Project Communication Protocols","text":""},{"location":"comms/#mqtt-message-queuing-telemetry-transport","title":"MQTT (Message Queuing Telemetry Transport)","text":""},{"location":"comms/#definition","title":"Definition:","text":"<p>MQTT is a lightweight messaging protocol designed for low-bandwidth, high-latency, or unreliable networks. It facilitates efficient communication between devices and software components.</p>"},{"location":"comms/#core-concept","title":"Core Concept:","text":"<ul> <li>Publish-Subscribe Model: MQTT operates on a publish-subscribe model. Devices or components 'publish' information to a topic, and others 'subscribe' to these topics to receive updates, enabling efficient data exchange.</li> </ul>"},{"location":"comms/#application-in-oasis","title":"Application in OASIS:","text":"<ul> <li>MQTT serves as the communication backbone in OASIS, connecting components like the helmet, repulsors, armor components, other weapons, etc.</li> <li>Its lightweight nature ensures minimal latency and resource usage, crucial for OASIS's real-time operations.</li> </ul>"},{"location":"comms/#advantages-for-oasis","title":"Advantages for OASIS:","text":"<ul> <li>Flexibility: Enables connection between any components.</li> <li>Scalability: Accommodates additional components easily.</li> <li>Reliability: Maintains stable communication, even in suboptimal network conditions.</li> </ul> <p>MQTT provides OASIS with a modular and robust communication framework, essential for its high-tech functionality.</p>"},{"location":"comms/#aura-communication-protocol","title":"A.U.R.A. Communication Protocol","text":"<p>Note: While typical device communication is over MQTT, v1 of the A.U.R.A. code uses serial over USB for data since we're already using that for charging.</p> <p>A.U.R.A. transmits crucial data through structured JSON messages, using the ArduinoJson.h library. Each message contains specific data fields relevant to the device's current readings. The data transmission is categorized into three main types:</p>"},{"location":"comms/#gps-data-transmission","title":"GPS Data Transmission","text":"<pre><code>{\n  \"device\": \"GPS\",\n  \"time\": \"&lt;time&gt;\",\n  \"date\": \"&lt;date&gt;\",\n  \"fix\": &lt;fix_status&gt;,\n  \"quality\": &lt;fix_quality&gt;,\n  \"latitude\": &lt;latitude_value&gt;,\n  \"latitudeDegrees\": &lt;latitude_in_degrees&gt;,\n  \"lat\": &lt;lat&gt;,\n  \"longitude\": &lt;longitude_value&gt;,\n  \"longitudeDegrees\": &lt;longitude_in_degrees&gt;,\n  \"lon\": &lt;lon&gt;,\n  \"speed\": &lt;speed&gt;,\n  \"angle\": &lt;angle&gt;,\n  \"altitude\": &lt;altitude&gt;,\n  \"satellites\": &lt;satellite_count&gt;\n}\n</code></pre> <p>Units:</p> <ul> <li>time : UTC time \"HH:MM:SS\"</li> <li>date : UTC date \"YYYY/MM/DD\"</li> <li>fix : 0/1</li> <li>latitude : decimal latitude</li> <li>latitudeDegrees : degrees latitude</li> <li>lat : N/S</li> <li>longitude : decimal longitude</li> <li>longitudeDegrees : degrees longitude</li> <li>lon : W/E</li> <li>speed : m/s</li> <li>altitude : m</li> </ul> <p>Notes:</p> <ul> <li>Real-time GPS data transmission including time, date, location, speed, altitude, and satellite information.</li> <li>Data fields are contingent on the status of the GPS fix.</li> <li>latitude and longitude is preferred in degrees at this time.</li> <li>lat and lon are only applied to decimal values</li> </ul>"},{"location":"comms/#motion-data-transmission","title":"Motion Data Transmission","text":"<pre><code>{\n  \"device\": \"Motion\",\n  \"format\": \"Orientation\",\n  \"heading\": &lt;heading&gt;,\n  \"pitch\": &lt;pitch&gt;,\n  \"roll\": &lt;roll&gt;\n}\n</code></pre> <p>Units:</p> <ul> <li>heading : degrees</li> <li>pitch : degrees</li> <li>roll : degrees</li> </ul> <p>Notes:</p> <ul> <li>Orientation data transmission, providing heading, pitch, and roll information.</li> <li>Key for understanding the spatial orientation of the helmet.</li> </ul>"},{"location":"comms/#environmental-data-transmission","title":"Environmental Data Transmission","text":"<pre><code>{\n  \"device\": \"Enviro\",\n  \"temp\": &lt;temperature&gt;,\n  \"humidity\": &lt;humidity&gt;\n}\n</code></pre> <p>Units:</p> <ul> <li>temp : \u00b0C</li> <li>humidity : percent</li> </ul> <p>Notes:</p> <ul> <li>Environmental information like temperature and humidity is transmitted.</li> <li>Vital for monitoring and adapting to surrounding environmental conditions.</li> </ul> <p>Each JSON message is serialized and sent via Serial, forming a standardized and efficient communication protocol within the O.A.S.I.S. system. This ensures precise and real-time data handling, integral to the system's functionality.</p>"},{"location":"comms/#spark-communication-protocol","title":"S.P.A.R.K. Communication Protocol","text":"<p>The S.P.A.R.K. system in the O.A.S.I.S. project transmits key data and commands to ensure precise control and interactive functionality. It uses JSON formatted messages, serialized and transmitted for efficient communication.</p>"},{"location":"comms/#regular-transmissions-from-remote-devices","title":"Regular Transmissions from Remote Devices","text":""},{"location":"comms/#voltage-data-transmission","title":"Voltage Data Transmission","text":"<pre><code>{\n  \"device\": \"&lt;topic&gt;\",\n  \"voltage\": &lt;rounded_voltage&gt;\n}\n</code></pre> <p>Units:</p> <ul> <li>voltage : volts</li> </ul> <p>Notes:</p> <ul> <li>Transmits voltage data, rounded to two decimal places. This data is used for device health monitoring to notify about low-battery conditions.</li> </ul>"},{"location":"comms/#temperature-data-transmission","title":"Temperature Data Transmission","text":"<pre><code>{\n  \"device\": \"&lt;topic&gt;\",\n  \"temp\": &lt;rounded_temperature&gt;\n}\n</code></pre> <p>Units:</p> <ul> <li> <p>temp : \u00b0C</p> </li> <li> <p>Sends temperature readings, rounded to two decimal places. Also used to monitor device health as well as the potential health of the wearer.</p> </li> </ul>"},{"location":"comms/#local-event-based-audio-commands","title":"Local Event-Based Audio Commands","text":""},{"location":"comms/#audio-playback-command","title":"Audio Playback Command","text":"<pre><code>{\n  \"device\": \"audio\",\n  \"command\": \"play\",\n  \"arg1\": &lt;sound_identifier&gt;,\n  \"arg2\": &lt;percent start&gt;\n}\n</code></pre> <ul> <li>Initiates audio playback for specific events.</li> <li><code>arg1</code> specifies the sound to be played. This is an audio file available on the playback device. Currently supported audio formats: Ogg Vorbis</li> <li><code>arg2</code> specifies the start percentage of the file. \"Where do you start playback?\"</li> </ul> <p>Developer Note: Percentage seems like an odd 'start time' here but it allows it to be relative to power-up, power-down light percentage. </p>"},{"location":"comms/#audio-stop-command","title":"Audio Stop Command","text":"<pre><code>{\n  \"device\": \"audio\",\n  \"command\": \"stop\",\n  \"arg1\": &lt;sound_identifier&gt;\n}\n</code></pre> <ul> <li>Stops audio playback for specific events.</li> <li><code>arg1</code> identifies which sound to stop. This should match the name of a previously played sound file.</li> </ul> <p>Each of these JSON messages is crafted to convey precise instructions and data to the S.P.A.R.K. system, contributing to a responsive and interactive user experience in the O.A.S.I.S. ecosystem.</p> <p>Developer To-Do: This start/stop playback system was developed when the application of this function was limited. For proper functionality in a much larger, complex system, IDs should be added to the play commands for accurate stopping of identical filenames.</p>"},{"location":"comms/#generic-device-commands","title":"Generic Device Commands","text":""},{"location":"comms/#command-configuration-for-oasis-devices","title":"Command Configuration for O.A.S.I.S. Devices","text":"<p>The <code>commands_config_nuevo.json</code> file specifies command types and actions applicable to different devices in the O.A.S.I.S. system. It outlines action words and corresponding JSON commands for execution.</p>"},{"location":"comms/#command-types","title":"Command Types","text":""},{"location":"comms/#boolean-commands","title":"Boolean Commands","text":"<p>Used for enabling or disabling features.</p>"},{"location":"comms/#actions","title":"Actions","text":"<ul> <li>Enable<ul> <li>Action Words: \"enable %device_name%\", \"turn on %device_name%\", etc.</li> <li>JSON Command: <code>{\"device\": \"%device_name%\", \"action\": \"enable\"}</code></li> </ul> </li> <li>Disable<ul> <li>Action Words: \"disable %device_name%\", \"turn off %device_name%\", etc.</li> <li>JSON Command: <code>{\"device\": \"%device_name%\", \"action\": \"disable\"}</code></li> </ul> </li> </ul>"},{"location":"comms/#analog-commands","title":"Analog Commands","text":"<p>Used for setting values or adjusting parameters.</p>"},{"location":"comms/#actions_1","title":"Actions","text":"<ul> <li>Set<ul> <li>Action Words: \"set %device_name% to %value%\", \"adjust %device_name% to %value%\", etc.</li> <li>JSON Command: <code>{\"device\": \"%device_name%\", \"action\": \"set\", \"value\": \"%value%\"}</code></li> </ul> </li> </ul>"},{"location":"comms/#usage","title":"Usage","text":"<p>Each command type encompasses specific actions. Action words are verbal commands interpreted by the system to execute predefined JSON commands. <code>%device_name%</code> and <code>%value%</code> are placeholders that will be replaced by specific device names and values during runtime.</p>"},{"location":"comms/#dawn-communication-protocol","title":"D.A.W.N. Communication Protocol","text":""},{"location":"comms/#text-to-speech-commands-for-dawn","title":"Text-to-Speech Commands for DAWN","text":"<p>D.A.W.N., the Digital Assistant for Wearable Neutronics, can interpret and execute Text-to-Speech (TTS) commands. These commands enable DAWN to convert text into spoken words, enhancing the interactive experience.</p>"},{"location":"comms/#command-structure","title":"Command Structure","text":"<p>The topic for DAWN commands is <code>dawn</code>. TTS commands are JSON-formatted and contain the following key-value pairs:</p> <pre><code>{\n  \"device\": \"text to speech\",\n  \"action\": \"&lt;action_type&gt;\",\n  \"value\": \"&lt;text_to_speak&gt;\"\n}\n</code></pre> <ul> <li>device: Specifies that the command is for the Text-to-Speech system.</li> <li>action: Defines the action to be taken, \"play\" for TTS reading.</li> <li>value: The text string that will be converted to speech.</li> </ul>"},{"location":"comms/#example-command","title":"Example Command","text":"<p>To have DAWN say \"Helmet connected.\", the command would be:</p> <pre><code>{\n  \"device\": \"text to speech\",\n  \"action\": \"play\",\n  \"value\": \"Helmet connected.\"\n}\n</code></pre> <p>From the command line:</p> <pre><code>mosquitto_pub -h &lt;IP&gt; -p &lt;port&gt; -t dawn -m \"{ \\\"device\\\": \\\"text to speech\\\", \\\"action\\\": \\\"play\\\", \\\"value\\\": \\\"Your hud is shutting down.\\\" }\"\n</code></pre>"},{"location":"comms/#functionality","title":"Functionality","text":"<ul> <li>Upon receiving this command, DAWN processes the `\"value\"`` field through its TTS system.</li> <li>The TTS system then audibly speaks the provided text.</li> <li>This feature is crucial for auditory feedback and interaction within the O.A.S.I.S. system.</li> </ul>"},{"location":"comms/#customization","title":"Customization","text":"<ul> <li>The TTS commands can be customized to convey a wide range of messages and information.</li> <li>Text in the <code>\"value\"</code> field can be modified to suit the specific needs of the situation or user interaction.</li> </ul>"},{"location":"credits/","title":"Credits","text":""},{"location":"credits/#credits","title":"Credits","text":""},{"location":"credits/#developers","title":"Developers","text":""},{"location":"credits/#kris-kersey-kersey-fabrications","title":"Kris Kersey - Kersey Fabrications","text":"<p>With over 20 years of experience in embedded software development, over 9 years as a cosplay fabricator, and over 5 years as a 3D printing YouTuber/Influencer, Kris is a passionate maker and cosplayer. He shares his knowledge of 3D printing and maker projects through his YouTube channel, Kersey Fabrications.</p> <p>Kris is the founder and lead developer of the O.A.S.I.S. Project.</p> <p>LinkedIn Profile</p>"},{"location":"credits/#artists","title":"Artists","text":""},{"location":"credits/#j6-executive-producer","title":"J6 - \"Executive Producer\"","text":"<p>Artist of all of the Iron Man-inspired artwork in the initial version of the MIRAGE project. J6 was an advisor for the look and feel of the UI and also brought extensive expertise to the project with their background in video game animation.</p>"},{"location":"dawn/","title":"D.A.W.N.","text":""},{"location":"dawn/#dawn-digital-assistant-for-wearable-neutronics-ai-assistant","title":"D.A.W.N. - Digital Assistant for Wearable Neutronics (AI Assistant)","text":"<p>These instructions are currently in the \"do this\" phase. This \"works for me\" and I welcome your feedback.</p> <p></p>"},{"location":"dawn/#application-notes","title":"Application Notes","text":"<ul> <li>OpenAI API - An OpenAI API key is required for the current implementation of the cloud AI using OpenAI. Getting an API key is currently beyond the scope of this document. Please see OpenAI's documentation for details.</li> <li>If you do not wish to use cloud AI or you only want local command support, there is a flag to disable it.</li> </ul>"},{"location":"dawn/#installation-notes-required-software","title":"Installation Notes (Required Software)","text":""},{"location":"dawn/#cmake-3271","title":"Cmake 3.27.1","text":"<ol> <li><code>tar xvf cmake-3.27.1.tar.gz</code></li> <li><code>cd cmake-3.27.1</code></li> <li><code>./configure --system-curl</code></li> <li><code>make -j8</code></li> <li><code>sudo make install</code></li> </ol>"},{"location":"dawn/#spdlog","title":"spdlog","text":"<ol> <li><code>git clone https://github.com/gabime/spdlog.git</code></li> <li><code>cd spdlog</code></li> <li><code>mkdir build &amp;&amp; cd build</code></li> <li><code>cmake .. &amp;&amp; make -j8</code></li> <li><code>sudo make install</code></li> </ol>"},{"location":"dawn/#espeak-ng-git","title":"espeak-ng (git)","text":"<p>Before we begin: <code>sudo apt purge espeak-ng-data libespeak-ng1 speech-dispatcher-espeak-ng</code></p> <ol> <li><code>git clone https://github.com/rhasspy/espeak-ng.git</code></li> <li><code>cd espeak-ng</code></li> <li><code>./autogen.sh</code></li> <li><code>./configure --prefix=/usr</code></li> <li><code>make -j8 src/espeak-ng src/speak-ng</code></li> <li><code>make</code></li> <li><code># make docs</code> - Skip? bash: no: command not found</li> <li><code>sudo make LIBDIR=/usr/lib/aarch64-linux-gnu install</code></li> </ol>"},{"location":"dawn/#onnxruntime-git","title":"Onnxruntime (git)","text":"<ol> <li><code>git clone --recursive https://github.com/microsoft/onnxruntime</code></li> <li><code>cd onnxruntime</code></li> <li><code>./build.sh --use_cuda --cudnn_home /usr/local/cuda-11.4 --cuda_home  /usr/local/cuda-11.4 --config MinSizeRel --update --build --parallel --build_shared_lib</code></li> <li> <p>Needed? - <code>./build.sh --use_cuda --cudnn_home /usr/local/cuda-11.4 --cuda_home  /usr/local/cuda-11.4 --config MinSizeRel --enable_pybind --parallel --build_wheel</code></p> <p>At this point, one test fails but it doesn't appear to be fatal to us. </p><pre><code>67% tests passed, 1 tests failed out of 3\n\nTotal Test time (real) = 342.80 sec\n\nThe following tests FAILED:\n1 - onnxruntime_test_all (Failed)\n</code></pre> </li> <li> <p><code>sudo cp -a build/Linux/MinSizeRel/libonnxruntime.so* /usr/local/lib/</code></p> </li> <li><code>sudo mkdir -p /usr/local/include/onnxruntime</code></li> <li><code>sudo cp include/onnxruntime/core/session/*.h /usr/local/include/onnxruntime</code></li> </ol>"},{"location":"dawn/#piper-phonemize-git","title":"piper-phonemize (git)","text":"<ol> <li><code>git clone https://github.com/rhasspy/piper-phonemize.git</code></li> <li><code>cd piper-phonemize</code><ol> <li><code>cd src &amp;&amp; cp ../../onnxruntime/include/onnxruntime/core/session/*.h .</code></li> <li><code>cd ..</code></li> </ol> </li> <li><code>mkdir build &amp;&amp; cd build</code></li> <li><code>cmake ..</code></li> <li><code>make</code></li> <li><code>sudo make install</code></li> <li>Needed? - <code>make python</code></li> </ol>"},{"location":"dawn/#piper-git","title":"piper (git)","text":"<ol> <li><code>git clone https://github.com/rhasspy/piper.git</code></li> <li><code>cd piper</code><ol> <li><code>vim src/cpp/CMakeLists.txt</code></li> <li>Add <code>/usr/local/include/onnxruntime</code> and <code>/usr/local/include/piper-phonemize</code> to <code>target_include_directories</code></li> </ol> </li> <li><code>make</code> - You'll get some errors on copies at the end but it builds.</li> </ol>"},{"location":"dawn/#kaldi-git-this-is-a-really-long-build-process","title":"kaldi (git) (This is a REALLY long build process!)","text":"<ol> <li><code>sudo apt-get install sox subversion</code></li> <li><code>sudo git clone -b vosk --single-branch --depth=1 https://github.com/alphacep/kaldi /opt/kaldi</code></li> <li><code>sudo chown -R $USER /opt/kaldi</code></li> <li><code>cd /opt/kaldi/tools</code></li> <li>Edit Makefile. Remove <code>-msse -msse2</code> from <code>openfst_add_CXXFLAGS</code></li> <li><code>make openfst cub</code> (Note: -j# doesn't seem to work here.) LONG BUILD</li> <li><code>./extras/install_openblas_clapack.sh</code></li> <li><code>cd ../src</code></li> <li><code>./configure --mathlib=OPENBLAS_CLAPACK --shared</code></li> <li><code>make -j 10 online2 lm rnnlm</code></li> <li><code>cd ../..</code></li> <li><code>sudo git clone https://github.com/alphacep/vosk-api --depth=1</code></li> <li><code>sudo chown -R $USER vosk-api</code></li> <li><code>cd vosk-api/src</code></li> <li><code>KALDI_ROOT=/opt/kaldi make -j8</code></li> <li><code>cd ../c</code></li> <li>Edit Makefile. Add the following to LDFLAGS: <code>$(shell pkg-config --libs cuda-11.4 cudart-11.4) -lcusparse -lcublas -lcusolver -lcurand</code><ol> <li><code>make</code></li> </ol> </li> <li>Choose a model:<ol> <li><code>wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip</code></li> <li><code>wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip</code></li> </ol> </li> <li><code>unzip vosk-model-en-us-0.22.zip</code></li> <li><code>ln -s vosk-model-en-us-0.22 model</code></li> <li><code>cp ../python/example/test.wav .</code></li> <li><code>./test_vosk</code></li> </ol>"},{"location":"dawn/#copy-some-files-over-for-compiling","title":"Copy some files over for compiling","text":"<ol> <li><code>cp -r vosk-model-en-us-0.22 SOURCE_DIR</code></li> <li><code>cp ../src/vosk_api.h ../src/libvosk.so SOURCE_DIR</code></li> </ol>"},{"location":"dawn/#build-dawn","title":"Build DAWN","text":"<ol> <li><code>mkdir build</code></li> <li><code>cd build</code></li> <li><code>cmake ..</code></li> <li><code>make</code></li> </ol>"},{"location":"dawn/#dawn-application-configuration-documentation-commands_config_nuevojson","title":"DAWN Application Configuration Documentation (<code>commands_config_nuevo.json</code>)","text":"<p>The DAWN application utilizes a sophisticated configuration file designed to enhance interactivity through local voice commands and actions. This documentation outlines the structure and purpose of each section within the file, focusing on how actions are defined and linked to specific devices, including audio settings customization.</p>"},{"location":"dawn/#types-and-actions","title":"Types and Actions","text":"<pre><code>{\n  \"types\": {\n     \"boolean\": {\n        \"actions\": {\n           \"enable\": {\n              \"action_words\": [\"enable %device_name%\", \"turn on %device_name%\", \"switch on %device_name%\", \"show %device_name%\", \"display %device_name%\", \"open %device_name%\", \"start %device_name%\"],\n              \"action_command\": \"{\\\"device\\\": \\\"%device_name%\\\", \\\"action\\\": \\\"enable\\\"}\"\n           },\n           \"disable\": {\n              \"action_words\": [\"disable %device_name%\", \"turn off %device_name%\", \"switch off %device_name%\", \"hide %device_name%\", \"close %device_name%\", \"stop %device_name%\"],\n              \"action_command\": \"{\\\"device\\\": \\\"%device_name%\\\", \\\"action\\\": \\\"disable\\\"}\"\n           }\n        }\n     }\n  }\n}\n</code></pre> <ul> <li><code>types</code>: Represent the different categories of settings that can be adjusted or monitored within the DAWN system. These include <code>boolean</code> for toggle settings, <code>analog</code> for value-based adjustments, <code>getter</code> for retrieving information, and <code>music</code> for controlling audio playback.</li> <li><code>actions</code>: Defined within each type, actions describe what operations can be performed. Each action has associated <code>action_words</code>, which are the voice commands recognized by DAWN to trigger the action, and an <code>action_command</code>, the MQTT JSON string sent to the target device to execute the action.</li> </ul>"},{"location":"dawn/#devices","title":"Devices","text":"<p>This section lists the various devices controlled by DAWN, detailing how voice commands translate into specific actions for each device:</p> <ul> <li><code>type</code>: Links the device to one of the defined types (e.g., boolean, analog), dictating the nature of its control.</li> <li><code>aliases</code>: Alternative names or phrases that can also refer to the device, enhancing the system's ability to recognize voice commands intended for it.</li> <li><code>topic</code>: The MQTT topic the device publishes to, ensuring that commands are accurately directed in the network.</li> </ul>"},{"location":"dawn/#audio-devices","title":"Audio Devices","text":"<p>Specific to the configuration of audio input and output devices, this section allows DAWN to correctly setup and utilize audio hardware. This is independent of the rest of the configuration.</p> <p>Each audio device is categorized by its function (e.g., <code>microphone</code>, <code>headphones</code>, <code>speakers</code>), with detailed configurations for effective operation.</p> <ul> <li><code>type</code>: Identifies the role of the audio device within the system (e.g., audio capture device for microphones).</li> <li><code>aliases</code>: Provides additional identification terms for each device, facilitating user interaction.</li> <li><code>device</code>: The system identifier for the hardware, used by DAWN to apply the correct settings.</li> </ul> <pre><code>  \"audio devices\": {\n     \"microphone\": {\n        \"type\": \"audio capture device\",\n        \"aliases\": [\"mic\", \"helmet mic\", \"audio input device\"],\n        \"device\": \"alsa_input.usb-Creative_Technology_Ltd_Sound_Blaster_Play__3_00128226-00.analog-stereo\"\n     },\n     \"headphones\": {\n        \"type\": \"audio playback device\",\n        \"aliases\": [\"helmet\"],\n        \"device\": \"combined\"\n     },\n     \"speakers\": {\n        \"type\": \"audio playback device\",\n        \"aliases\": [\"speaker\", \"loud speakers\", \"loud speaker\", \"chest speaker\"],\n        \"device\": \"combined\"\n     }\n  }\n</code></pre> <p>Hints:</p> <ul> <li><code>pactl list short sinks</code></li> <li><code>pactl list short sources</code></li> <li>Set your audio devices: <code>commands_config_nuevo.json</code></li> </ul>"},{"location":"dawn/#run-dawn","title":"Run DAWN","text":"<ol> <li><code>./dawn</code></li> </ol>"},{"location":"dawn/#credits","title":"Credits","text":"<p>Initial adaptation from the piper project: https://github.com/rhasspy/piper</p> <p>Piper and the language models are covered under the MIT license. Vosk Licensed under the Apache License, Version 2.0.</p>"},{"location":"mirage/","title":"M.I.R.A.G.E.","text":""},{"location":"mirage/#mirage-multi-input-reconnaissance-and-guidance-environment-heads-up-display","title":"M.I.R.A.G.E. - Multi-Input Reconnaissance and Guidance Environment (Heads-Up Display)","text":""},{"location":"mirage/#application-notes","title":"Application Notes","text":"<ul> <li>Google API/Maps - A Google API key is required for the current implementation of the maps overlay for access to Google Maps. Getting an API key is currently beyond the scope of this document. Please see Google's documentation for details.   There are plans to rewrite the maps code to support an open API.</li> </ul>"},{"location":"mirage/#hardware","title":"Hardware","text":"<p>The following hardware is what was used to create the original helmet.</p>"},{"location":"mirage/#embedded-system-options","title":"Embedded System Options","text":"<ul> <li> <p>NVIDIA Jetson Orin Nano Developer Kit</p> <p>Entry level Jetson for the OASIS project. Limited memory and no dedicated video encoders. Plenty of power otherwise.</p> <p>Amazon: https://amzn.to/3TD0vAW</p> </li> <li> <p>NVIDIA Jetson Orin NX 16GB</p> <p>Power Jetson module that I'm currently using on my system. For my system, I'm using the NVIDIA Jetson Orin Nano kit board with an Orin NX 16GB module. Here are a couple of options that /should/ work but are personally untested.</p> <ul> <li> <p>Yahboom Jetson Orin NX Series 16GB Development Board Kit</p> <p>Amazon: https://amzn.to/4aDuqQj</p> </li> <li> <p>Waveshare Jetson Orin NX AI Development Kit, JETSON-ORIN-NX-DEV-KIT (16GB)</p> <p>Waveshare: https://www.waveshare.com/product/jetson-orin-nx-16g-dev-kit.htm?sku=24222</p> </li> <li> <p>reComputer J4012-Edge AI Device with NVIDIA Jetson Orin\u2122 NX 16GB module</p> <p>Seeed Studio: https://www.seeedstudio.com/reComputer-J4012-p-5586.html</p> </li> </ul> </li> <li> <p>Original System: NVIDIA Jetson Xavier NX (Discontinued)</p> </li> </ul>"},{"location":"mirage/#displays","title":"Displays","text":"<ul> <li> <p>Wisecoco 2.9 Inch 2880*1440 2K Dual LCD Screen For VR AR Headset Windows Mixed Reality Display 120hz DP to MIPI Driver Board</p> <p>AliExpress: https://s.click.aliexpress.com/e/_DeQX2lT</p> </li> <li> <p>iWiner Mini DisplayPort to DisplayPort Cable, 6Ft</p> <p>Amazon: https://amzn.to/43IxTL7</p> </li> <li> <p>Alternative DisplayPort: Toptrend Mini Displayport Cable 6ft</p> <p>Amazon: https://amzn.to/3vBOhR4</p> </li> <li> <p>Duttek Mini DisplayPort Cable, 90 Degree</p> <p>Amazon: https://amzn.to/3VJRHvN</p> </li> </ul>"},{"location":"mirage/#cameras","title":"Cameras","text":"<ul> <li> <p>Arducam Mini 12.3MP HQ Camera - IMX477 (x2)</p> <p>Amazon: https://amzn.to/4aw8vuA</p> </li> <li> <p>Arducam CSI to HDMI Cable Extension Module (x2 sets)</p> <p>Amazon: https://amzn.to/49orFS3</p> </li> <li> <p>Monoprice - 124184 High Speed HDMI Cable - 3 Feet - Black (x2)</p> <p>Amazon: https://amzn.to/49kXFqe</p> </li> </ul>"},{"location":"mirage/#installation-notes-required-software","title":"Installation Notes (Required Software)","text":"<p>After you've installed the OS on the Jetson, do this first.</p> <ol> <li>Update everything. <pre><code>sudo apt update\nsudo apt upgrade\n</code></pre></li> <li> <p>Install necessary packages. <code>sudo apt-get install cmake libudev-dev libxext-dev libwebp-dev libpulse-dev libvorbis-dev libjson-c-dev libsamplerate-dev libfreetype6-dev libcurl4-openssl-dev nvidia-jetpack libmosquitto-dev mosquitto libsndfile-dev</code></p> </li> <li> <p>Manually install the latest SDL libraries. (Actually the distro ones should work now.)</p> <ul> <li>SDL2 (latest 2.28.2)</li> <li>SDL2_image (latest 2.6.3)</li> <li>SDL2_ttf (latest 2.20.2)</li> </ul> </li> <li> <p>Setup IO (Cameras, SPI)</p> <ol> <li><code>sudo /opt/nvidia/jetson-io/jetson-io.py</code></li> <li>Configure Jetson 40pin Header-&gt;Configure header pins manually-&gt;Enable 'spi1'-&gt;Save pin changes</li> <li>Configure Jetson 24pin CSI Connector-&gt;Configure for compatible hardware-&gt;Camera IMX219 Dual OR Camera IMX477 Dual OR Camera IMX477 Dual 4 Lane-&gt;Save pin changes</li> <li>Save and exit without rebooting</li> </ol> </li> <li> <p>Install Jetson Inference (for Object Detection)</p> <ol> <li>(https://github.com/dusty-nv/jetson-inference/blob/master/docs/building-repo-2.md)</li> <li><code>git clone https://github.com/dusty-nv/jetson-inference</code></li> <li><code>cd jetson-inference</code></li> <li><code>git submodule update --init</code></li> <li><code>mkdir build</code></li> <li><code>cd build</code></li> <li><code>cmake ..</code></li> <li><code>make -j8</code></li> <li><code>sudo make install</code></li> </ol> </li> <li> <p>Update user permissions.</p> <ol> <li>Add groups to user: <code>dialout</code></li> </ol> </li> </ol>"},{"location":"mirage/#build-mirage","title":"Build MIRAGE","text":"<ol> <li><code>mkdir build</code></li> <li><code>cd build</code></li> <li><code>cmake ..</code></li> <li><code>make</code></li> </ol>"},{"location":"mirage/#mirage-configuration","title":"MIRAGE Configuration","text":"<p>Welcome to the MIRAGE Configuration Guide! The MIRAGE UI is designed with flexibility at its core, allowing for a fully customizable experience through the <code>config.json</code> file. This powerful feature enables the integration of both static and animated graphics, text customization (including font and size), and the addition of unique elements positioned precisely with x/y coordinates and scaling. Moreover, UI elements can be effortlessly toggled on or off with the use of hotkeys and voice commands. While the current configuration offers a broad range of features, we anticipate further enhancements as more users engage with the system. Your feedback is crucial to perfecting the MIRAGE experience.</p> <p>The <code>config.json</code> file uses JSON, a straightforward and versatile format, to organize the MIRAGE UI's settings. It's designed to be user-friendly, allowing for easy tweaks to the look and functionality of the UI. JSON structures the configuration details in a clear way, enabling you to adjust everything from screen layout to interactive features with minimal fuss. This approach combines accessibility with the flexibility needed for precise customization, making it manageable for both technical and less technical users alike.</p> <p>Note: Due to some rapid coding, many of the settings are case sensitive. This may change in the future but you have been warned.</p>"},{"location":"mirage/#global-configuration-section","title":"Global Configuration Section","text":""},{"location":"mirage/#example-global-section","title":"Example Global Section","text":"<p>Below is an example of a Global section in the configuration file. This section outlines the primary settings for the MIRAGE UI, such as dimensions, paths for resources, and specific functionalities:</p> <pre><code>{\n   \"Global\": {\n      \"Height\": 1440,\n      \"Width\": 1440,\n      \"Image Path\": \"ui_assets/mk2/\",\n      \"Font Path\": \"ui_assets/fonts/\",\n      \"Sound Path\": \"sound_assets/\",\n      \"Stereo Offset\": -90,\n      \"Wifi\": \"wlan0\",\n      \"Invert Compass\": true,\n      \"Stream Width\": 800,\n      \"Stream Height\": 400,\n      \"Stream Dest IP\": \"192.168.10.170\",\n      \"Armor dest_x\": 70,\n      \"Armor dest_y\": 900,\n      \"Armor dest_w\": 450,\n      \"Armor dest_h\": 450,\n      \"Armor notice dest_x\": 220,\n      \"Armor notice dest_y\": 220,\n      \"Armor notice dest_w\": 1000,\n      \"Armor notice dest_h\": 1000,\n      \"Armor notice timeout\": 5\n   }\n}\n</code></pre> <p>The \"Global\" section of the <code>config.json</code> file is your command center for setting up the foundational aspects of the MIRAGE UI. Here's a breakdown to help you configure the system to its maximum potential:</p> <ul> <li> <p><code>Height</code> &amp; <code>Width</code>: Set the default height and width (<code>1440</code> pixels) for each eye of the UI display. This establishes the canvas size on which all UI elements will be placed.</p> </li> <li> <p><code>Image Path</code>: Designate the directory (<code>ui_assets/mk2/</code>) where UI images are stored. This path is critical for loading all graphical elements.</p> </li> <li> <p><code>Font Path</code>: Specify the path (<code>ui_assets/fonts/</code>) to the directory containing font files. This allows for text customization across the UI.</p> </li> <li> <p><code>Sound Path</code>: Determine where sound files are located (<code>sound_assets/</code>). Sounds can be triggered via MQTT messages.</p> </li> <li> <p><code>Stereo Offset</code>: Adjust the stereo visual effect with a pixel (<code>-90</code>) offset. This can enhance the 3D experience for certain visuals.</p> </li> <li> <p><code>Wifi</code>: Identify the network interface (e.g., <code>wlan0</code>) used for wireless connections. This setting is essential for features that require querying the device.</p> </li> <li> <p><code>Invert Compass</code>: Toggle the compass inversion (<code>true</code> or <code>false</code>). Useful for adjusting compass behavior to match user preferences. Some devices act weird and require flipping.</p> </li> <li> <p><code>Stream Width</code> &amp; <code>Stream Height</code>: Configure the dimensions for network streaming content (<code>800</code>x<code>400</code> pixels). This resolution impacts device performance and network performance.</p> </li> <li> <p><code>Stream Dest IP</code>: Set the destination IP address (<code>192.168.10.170</code>) for streaming content. This directs where the streamed data should be sent.</p> </li> <li> <p>Armor Placement: Customize the position and size of the armor display on the UI using <code>Armor dest_x</code>, <code>Armor dest_y</code>, <code>Armor dest_w</code>, and <code>Armor dest_h</code>. This allows for precise control over how and where the armor status is shown.</p> </li> <li> <p>Armor Notice Placement &amp; Timeout: Fine-tune the positioning and display duration of armor-related notifications with <code>Armor notice dest_x</code>, <code>Armor notice dest_y</code>, <code>Armor notice dest_w</code>, <code>Armor notice dest_h</code>, and <code>Armor notice timeout</code>. These settings ensure critical information is prominently and timely displayed.</p> </li> </ul> <p>This section is foundational to the overall operation of the MIRAGE UI, providing essential settings that affect the display, performance, and functionality of the system. By customizing these parameters, you can tailor the MIRAGE experience to meet your specific needs and preferences.</p>"},{"location":"mirage/#elements-section","title":"Elements Section","text":"<p>The \"Elements\" section of the <code>config.json</code> file specifies the individual UI components that make up the MIRAGE interface. These elements can be anything from animated graphics, static images, and text labels to special components defined in the software. Each element is defined by a set of properties that determine its appearance, behavior, and placement within the UI.</p>"},{"location":"mirage/#types-of-elements","title":"Types of Elements","text":"<p>There are several types of elements you can include in the MIRAGE UI, each serving a unique function:</p> <ul> <li><code>intro</code>: Used for the animated introduction presented at application startup. <pre><code>{\n    \"type\": \"intro\",\n    \"file\": \"IronMan-UI-Intro.json\",\n    \"dest_x\": 0,\n    \"dest_y\": 0,\n    \"angle\": 0\n}\n</code></pre></li> <li><code>special</code>: Designates elements with specific, often dynamic, functionalities like altitude or pitch displays. <pre><code>{\n    \"type\": \"special\",\n    \"name\": \"altitude\",\n    \"file\": \"IronMan-UI-Altitude-Animated-1.json\",\n    \"dest_x\": 0,\n    \"dest_y\": 0,\n    \"angle\": 0,\n    \"layer\": 0\n}\n</code></pre></li> <li><code>static</code>: Represents non-animated images or icons. <pre><code>{\n    \"type\": \"static\",\n    \"file\": \"IronMan-UI-PitchBox.png\",\n    \"dest_x\": 165,\n    \"dest_y\": 696,\n    \"angle\": 0,\n    \"layer\": 0\n}\n</code></pre></li> <li><code>text</code>: Displays text on the UI. <pre><code>{\n    \"type\": \"text\",\n    \"string\": \"*PITCH*\",\n    \"font\": \"devgothic.ttf\",\n    \"color\": \"0x00, 0xF5, 0xFC, 0xFF\",\n    \"size\": 24,\n    \"dest_x\": 185,\n    \"dest_y\": 707,\n    \"halign\": \"left\",\n    \"angle\": 0,\n    \"layer\": 1\n}\n</code></pre></li> <li><code>animated</code>: For animated graphics created with animation sheets and a config json file. <pre><code>{\n    \"name\": \"armor\",\n    \"type\": \"animated\",\n    \"file\": \"IronMan-UI-Pedestal-Animated-V2.json\",\n    \"dest_x\": 180,\n    \"dest_y\": 1115,\n    \"width\": 230,\n    \"angle\": 0,\n    \"layer\": 0\n}\n</code></pre></li> <li><code>record-ui</code>: This element dynamically changes its graphic to visually indicate the current recording and streaming status, using different images to represent not recording, recording, streaming, and both recording and streaming simultaneously. <pre><code>{\n    \"type\": \"record-ui\",\n    \"file\": \"IronMan-UI-ClockBox.png\",\n    \"file_r\": \"IronMan-UI-ClockBox-R.png\",\n    \"file_s\": \"IronMan-UI-ClockBox-S.png\",\n    \"file_rs\": \"IronMan-UI-ClockBox-RS.png\",\n    \"dest_x\": 595,\n    \"dest_y\": 109,\n    \"angle\": 0,\n    \"fixed\": 0,\n    \"layer\": 0\n}\n</code></pre></li> </ul>"},{"location":"mirage/#common-properties","title":"Common Properties","text":"<p>Certain properties are shared across all (or most) types of elements, allowing for consistent customization and control:</p> <ul> <li><code>type</code>: Specifies the type of the element (e.g., <code>intro</code>, <code>special</code>, <code>static</code>, <code>text</code>, <code>animated</code>).</li> <li><code>name</code>: Used to provide a unique identifier for the element.</li> <li><code>file</code>: The path to the file used by the element.</li> <li><code>dest_x</code> and <code>dest_y</code>: The x and y coordinates where the element will be positioned on the UI.</li> <li><code>width</code> and <code>height</code>: The dimensions of the element, allowing you to specify how wide and tall the element should be. This is particularly useful for resizing images or adjusting the area for text elements.</li> <li><code>angle</code>: The rotation angle of the element. You can indicate a specific angle or there are two special arguments (this is specifically used for the the reticle):<ul> <li><code>roll</code>: Use the roll angle to indicate the angle of this element.</li> <li><code>opposite roll</code>: Use the inverse roll angle to indicate the angle of the element. (-1.0 * roll)</li> </ul> </li> <li><code>layer</code>: Determines the z-index or layer of the element, with higher numbers appearing above (or in front of) lower ones.</li> <li><code>hotkey</code>: Designates a keyboard shortcut (e.g., \"i\") assigned to the element, enabling users to quickly enable or disable the element.</li> <li><code>enabled</code>: A boolean (<code>1</code> or <code>0</code>) indicating whether the element is active and visible in the UI. This property allows for the dynamic toggling of elements, making it possible to show or hide them based on specific conditions or user interactions.</li> </ul>"},{"location":"mirage/#type-specific-properties","title":"Type-Specific Properties","text":"<p>While many properties are universal, some are specific to certain element types, allowing for more detailed customization:</p> <ul> <li> <p><code>special</code> element: In the MIRAGE UI, \"special\" elements are dynamic components designed to display real-time information and interactive data, each identified by a unique <code>name</code>. Here\u2019s a breakdown of these elements:</p> <ul> <li><code>altitude</code>: Shows how high the user is, useful for applications needing elevation data.</li> <li><code>pitch</code>: Displays the tilt angle of the device, crucial for maintaining orientation in navigation or remote-controlled operations.</li> <li><code>heading</code>: Provides directional information, helping users to navigate by showing which way they\u2019re facing relative to magnetic north.</li> <li><code>map</code>: Offers near real-time mapping and location tracking via downloaded maps based on GPS info.</li> <li><code>wifi</code>: Indicates the strength of the Wi-Fi connection, essential for activities that require internet access.</li> <li><code>detect</code> Visualizes the detection of objects, alerting users to changes or important information in their environment.</li> </ul> </li> <li> <p><code>text</code> element: This element brings dynamic textual content to the interface, ranging from static labels to real-time data displays. These elements are highly customizable, allowing for precise control over appearance and alignment. A unique aspect of text elements is their ability to interpret certain patterns, specifically strings enclosed in asterisks (e.g., STRING), as special values that the system dynamically replaces with actual data. Below is a detailed look at the properties specific to text elements:</p> <ul> <li><code>string</code>: Determines the text displayed by the element. Strings encapsulated by asterisks represent special dynamic values that the system automatically updates with real-time information. Examples include <code>*PITCH*</code>, <code>*FPS*</code>, <code>*COMPASS*</code>, <code>*LATLON*</code>, <code>*CPU*</code>, <code>*MEM*</code>, <code>*FAN*</code>, <code>*HELMTEMP*</code>, and <code>*HELMHUM*</code>. These placeholders are replaced with actual data, such as current pitch angle, frames per second, compass direction, geographic coordinates, CPU usage, memory usage, fan speed, helmet temperature, and helmet humidity, respectively.</li> <li><code>font</code>: Specifies the filename of the font file used for rendering the text. This allows for a variety of typographic styles to suit different UI themes.</li> <li><code>color</code>: Sets the text color in RGBA format (e.g., \"0xFF, 0xFF, 0xFF, 0xFF\" for white). This property enables the text to stand out against the background and align with the UI's color scheme.</li> <li><code>size</code>: Defines the font size of the text. Adjusting this property ensures that the text fits well within its designated area and remains legible across different devices and resolutions.</li> <li><code>halign</code>: Specifies the horizontal alignment of the text within its container. Options include \"left\", \"center\", and \"right\", providing flexibility in how text is positioned and presented in the UI.</li> </ul> </li> <li> <p><code>record-ui</code> element: This element is a specialized component designed to visually indicate the state of recording and streaming activities. This element can change its appearance based on the current recording and streaming status, providing immediate visual feedback to the user. Here\u2019s how it works and what each property means:</p> <ul> <li><code>file</code>: The default graphic displayed when neither recording nor streaming is active. This serves as the baseline appearance.</li> <li><code>file_r</code>: The graphic to display when recording is in progress. It visually differentiates from the non-recording state to alert users that recording has commenced.</li> <li><code>file_s</code>: The graphic shown during streaming. This distinct visual cue informs users that streaming is currently active.</li> <li><code>file_rs</code>: The graphic used when both recording and streaming are simultaneously active. This combination graphic ensures users are aware of both operations happening concurrently.</li> </ul> </li> </ul>"},{"location":"mirage/#components-section-documentation","title":"Components Section Documentation","text":"<p>The \"Components\" section of the <code>config.json</code> is dedicated to monitoring various parts of the armor, providing real-time status updates through a visually intuitive interface. Each entry in this section corresponds to a specific armor component, with details on how it should be visually represented under different conditions. Here\u2019s a breakdown of the properties used to define each component:</p> <pre><code>{\n\"Components\": [\n    {\n        \"name\": \"Helmet\",\n        \"device\": \"helmet\",\n        \"base file\": \"FullBodyBlue/FullBody1.png\",\n        \"online file\": \"FullBodyGreen/FullBody1Green.png\",\n        \"warning file\": \"FullBodyYellow/FullBody1Yellow.png\",\n        \"offline file\": \"FullBodyRed/FullBody1Red.png\"\n    }\n}\n</code></pre>"},{"location":"mirage/#component-properties","title":"Component Properties","text":"<ul> <li><code>name</code>: The human-readable name of the armor component, intended for display purposes to make identification straightforward for the user.</li> <li><code>device</code>: Specifies the MQTT topic that the component publishes to, serving as a unique identifier for data communication and monitoring.</li> <li><code>base file</code>: The visual representation (typically in blue) of the component before any connection has been established, indicating the initial or standby state.</li> <li><code>online file</code>: The file (usually green) shown once a connection to the component has been successfully made, signaling that the component is active and functioning.</li> <li><code>warning file</code>: The file (commonly yellow) displayed when the component enters a warning state, such as overheating or low battery, prompting user attention to potential issues.</li> <li><code>offline file</code>: The visual (typically red) used to indicate that the component has lost connection or is otherwise not communicating, alerting the user to a significant problem.</li> </ul>"},{"location":"opensource/","title":"Open Source and Special Thanks","text":""},{"location":"opensource/#open-source-projects-and-special-thanks","title":"Open Source Projects and Special Thanks","text":""},{"location":"opensource/#open-source-projects","title":"Open Source Projects","text":"<p>The software on this page is either used by the OASIS Project or related to the project's work.</p> <ul> <li>Simple DirectMedia Layer</li> <li>JSON-C</li> <li>Vorbis Audio Compression</li> <li>Eclipse Mosquitto</li> <li>Jetson Inference</li> <li>Piper</li> <li>Kaldi ASR</li> <li>Vosk Speech Recognition</li> </ul>"},{"location":"opensource/#special-thanks","title":"Special Thanks","text":"<ul> <li>How to Run a ChatGPT-Like LLM on NVIDIA Jetson board by Nurgaliyev Shakhizat - A fantastic article that game me ideas and inspiration.</li> <li>NVIDIA Jetson Generative AI Lab - A great place to get started running edge AI applications on NVIDIA Jetson hardware.</li> <li>Jetson Inference and other Open Source Projects by Dustin Franklin - Dusty is a fantastic developer and technology communicator. His work contributed greatly to some of the early work on this project.</li> </ul>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#the-oasis-project-overview","title":"The O.A.S.I.S. Project Overview","text":""},{"location":"overview/#note-on-the-naming-of-these-components","title":"Note on the naming of these components.","text":"<p>Please note that all of these components were named to thematically sound like part of the O.A.S.I.S. Project. In many cases, the name was brainstormed attempting to find a fun acronym to back it up. Please do not take these names too seriously. They are conceived in the spirit of Tony Stark and are not to be taken too literally.</p> <p>The O.A.S.I.S. Project GitHub Homepage</p>"},{"location":"overview/#project-components","title":"Project Components","text":""},{"location":"overview/#atlas-advanced-technical-library-and-archival-system-documentation","title":"A.T.L.A.S. - Advanced Technical Library and Archival System (Documentation)","text":"<p>ATLAS on GitHub</p> <p>This is the project's documentation. Anything extra that isn't on this site can be found here. There may not be anything here now but detailed APIs and code documentation should live here.</p>"},{"location":"overview/#aura-advanced-utility-for-reliable-acquisition-embedded-helmet-firmware","title":"A.U.R.A - Advanced Utility for Reliable Acquisition (Embedded Helmet Firmware)","text":"<p>AURA on GitHub</p> <p>This is the embedded firmware for the helmet. It communicates to the HUD for all of the environmental sensor readings.</p>"},{"location":"overview/#beacon-blueprint-engineering-and-component-organizational-nexus-cad-files","title":"B.E.A.C.O.N. - Blueprint Engineering And Component Organizational Nexus (CAD Files)","text":"<p>BEACON on GitHub</p> <p>This is not only a software project but also a hardware project full of custom parts and 3D models. If you're looking for 3D printable models and details of assets owned by this project, this is the repository.</p>"},{"location":"overview/#dawn-digital-assistant-for-wearable-neutronics-ai-assistant","title":"D.A.W.N. - Digital Assistant for Wearable Neutronics (AI Assistant)","text":"<p>DAWN on GitHub</p> <p>Looking for J.A.R.V.I.S. or F.R.I.D.A.Y. integration? This is my A.I. assistant. It's specially designed with the following goals:</p> <ul> <li>Command-first processing - A special JSON file defines local commands first, then sends unknown text to an LLM for processing.</li> <li>OpenAI specially configured - OpenAI has been tweaked to provide helpful feedback with some personality.</li> <li>Speech-to-Text (ASR) chosen to be accurate and processor-efficient.</li> <li>Text-to-Speech (TTS) chosen to sound life-like and have a good UK dialect.</li> </ul>"},{"location":"overview/#genesis-general-nexus-for-experimental-software-and-informative-scripts-odds-and-ends","title":"Ge.N.E.S.I.S. - GEneral Nexus for Experimental Software and Informative Scripts (Odds and Ends)","text":"<p>GENESIS on GitHub</p> <p>If I needed a place to store something and it doesn't fit in elsewhere, it goes here. Things like helpful scripts, etc.</p>"},{"location":"overview/#mirage-multi-input-reconnaissance-and-guidance-environment-heads-up-display","title":"M.I.R.A.G.E. - Multi-Input Reconnaissance and Guidance Environment (Heads-Up Display)","text":"<p>MIRAGE on GitHub</p> <p>This is the display for all of the information in the suite. It interacts with all of the components and can be controlled with keyboard or voice through DAWN.</p>"},{"location":"overview/#spark-sensor-based-positioning-and-actuation-repulsor-kinetics-embedded-hand-firmware","title":"S.P.A.R.K. - Sensor-based Positioning and Actuation Repulsor Kinetics (Embedded Hand Firmware)","text":"<p>SPARK on GitHub</p> <p>Repulsors in the palm of your hands, motion-controlled, lights, sound, wireless.</p>"},{"location":"spark/","title":"S.P.A.R.K.","text":""},{"location":"spark/#spark-sensor-based-positioning-and-actuation-repulsor-kinetics-embedded-hand-firmware","title":"S.P.A.R.K. - Sensor-based Positioning and Actuation Repulsor Kinetics (Embedded Hand Firmware)","text":"<p>This code is a healthy mix of example code from various libraries with a special thanks to Adafruit for their awesome hardware and software.</p> <p>Note: I will have a circuit diagram in the future. This is a pretty simple one though. All of the devices are I2C devices that can be daisy-chained and it's powered by USB.</p>"},{"location":"spark/#hardware","title":"Hardware","text":"<ul> <li>Adafruit QT Py ESP32-S3</li> <li>Adafruit LSM6DSO32</li> <li>NeoPixel Jewel - 7 x 5050 RGB LED</li> <li>NeoPixel Ring - 12 x 5050 RGB LED</li> </ul>"},{"location":"spark/#libraries","title":"Libraries","text":"<ul> <li>ArduinoMqttClient</li> <li>WiFi</li> <li>Adafruit LSM6DSO32</li> <li>ArduinoJson</li> <li>FastLED</li> </ul>"},{"location":"spark/#building","title":"Building","text":"<p>This firmware is currently being built in the Arduino IDE using the libraries and target hardware mentioned above.</p>"},{"location":"videos/","title":"Videos","text":""},{"location":"videos/#videos-about-this-project","title":"Videos about this project!","text":""},{"location":"videos/#original-iron-man-hud-video","title":"Original Iron Man HUD Video","text":""},{"location":"videos/#the-tech-behind-wireless-iron-man-repulsors","title":"The Tech Behind Wireless Iron Man Repulsors","text":""},{"location":"videos/#iron-man-hud-on-nvidia-jetson-orin-nano","title":"Iron Man HUD on NVIDIA Jetson Orin Nano","text":""},{"location":"videos/#3d-printed-metal-iron-man-repulsors-with-hud-monitoring","title":"3D Printed Metal Iron Man Repulsors with HUD Monitoring","text":""},{"location":"videos/#building-iron-man-gauntlets-from-prototype-to-resin-printing","title":"Building Iron Man Gauntlets: From Prototype to Resin Printing","text":""},{"location":"videos/#resin-3d-printing-iron-man-gauntlets-the-complete-process","title":"Resin 3D Printing Iron Man Gauntlets: The Complete Process","text":""},{"location":"videos/#real-iron-man-tech-helmet-with-ai-assistant","title":"Real Iron Man Tech: Helmet with AI Assistant","text":""},{"location":"videos/#working-iron-man-helmet-walk-around-nvidia-gtc-2024","title":"Working Iron Man Helmet Walk-around: NVIDIA GTC 2024","text":""},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2023/12/04/hello-mr-stark/","title":"Hello Mr. Stark.","text":""},{"location":"blog/2023/12/04/hello-mr-stark/#hello-mr-stark","title":"Hello Mr. Stark.","text":"<p>This is the home of the O.A.S.I.S. project. What is Oasis? More to come soon.</p> <p>This is even more.</p>"},{"location":"exclude/example/","title":"Example/Demo Page","text":""},{"location":"exclude/example/#exampledemo-page","title":"Example/Demo Page","text":"<p>This is the demo page provided as site creation. I'm just playing around here.</p> <p>For full documentation visit mkdocs.org.</p>"},{"location":"exclude/example/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"exclude/example/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"exclude/example/#code-examples","title":"Code Examples","text":"<p>Test <code>code</code>. Let's test it.</p> helloworld.c<pre><code>#include &lt;stdio.h&gt;\nint main(int argc, char **argc) {\n    printf(\"Hello world!\");\n}\n</code></pre> <p></p>"},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/category/intro/","title":"Intro","text":""}]}